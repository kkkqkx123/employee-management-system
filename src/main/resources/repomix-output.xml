This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
application-dev.properties
application-hybrid.properties
application-local.properties
application-prod.properties
application-staging.properties
application.properties
db/migration/.gitkeep
db/migration/V0__Initial_baseline.sql
db/migration/V1__Create_security_tables.sql
db/migration/V2__Create_departments_table.sql
db/migration/V3__Create_positions_table.sql
db/migration/V4__Create_employees_table.sql
db/migration/V5__Create_email_tables.sql
db/migration/V6__Create_chat_tables.sql
db/migration/V7__Create_notification_tables.sql
db/migration/V8__Create_payroll_tables.sql
logback-spring-simple.xml
logback-spring.xml
logback-spring.xml.backup
static/.gitkeep
templates/.gitkeep
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="application-dev.properties">
# Development Environment Configuration
# Employee Management System - Development Profile

# Development Server Configuration
server.error.include-stacktrace=on_param
server.error.include-exception=true

# Development Database Configuration
spring.datasource.url=jdbc:postgresql://localhost:5432/employee_management_dev
spring.datasource.username=employee_admin
spring.datasource.password=dev_password

# Development JPA Configuration
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.use_sql_comments=true

# Development Redis Configuration
spring.data.redis.host=localhost
spring.data.redis.port=6379
spring.data.redis.database=1

# Development Security Configuration
jwt.secret=developmentSecretKeyNotForProduction
encryption.key=developmentEncryptionKeyNotForProduction

# Development Email Configuration (Console output)
spring.mail.host=localhost
spring.mail.port=1025
spring.mail.username=
spring.mail.password=
spring.mail.properties.mail.smtp.auth=false
spring.mail.properties.mail.smtp.starttls.enable=false

# Development Logging Configuration
logging.level.com.example.demo=DEBUG
logging.level.org.springframework.web=DEBUG
logging.level.org.springframework.security=DEBUG
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE
logging.level.org.springframework.cache=DEBUG

# Development Actuator Configuration
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always

# Development CORS Configuration (Allow all origins for development)
cors.allowed-origins=http://localhost:3000,http://localhost:5173
cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
cors.allowed-headers=*
cors.allow-credentials=true

# Development File Storage
file.upload.directory=./uploads/dev
file.temp.directory=./temp/dev
</file>

<file path="application-hybrid.properties">
# Hybrid Environment Configuration
# Employee Management System - Hybrid Development Profile (WSL PostgreSQL + Docker Redis)

# Server Configuration
server.port=8080
server.servlet.context-path=/api
server.error.include-message=on_param
server.error.include-binding-errors=on_param
server.error.include-stacktrace=on_param
server.error.include-exception=true

# PostgreSQL Database Configuration (Docker/Local)
spring.datasource.url=jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:employee_management}
spring.datasource.username=${DB_USERNAME:employee_admin}
spring.datasource.password=${DB_PASSWORD:dev_password123}
spring.datasource.driver-class-name=org.postgresql.Driver

# HikariCP Connection Pool Configuration
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.max-lifetime=1200000
spring.datasource.hikari.pool-name=EmployeeManagementPool

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.use_sql_comments=true
spring.jpa.properties.hibernate.jdbc.batch_size=50
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true

# Redis Configuration (Docker/Local)
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.database=${REDIS_DB:1}
spring.data.redis.password=${REDIS_PASSWORD:}
spring.cache.redis.time-to-live=3600s

# JWT Configuration
jwt.secret=${JWT_SECRET:developmentSecretKeyNotForProduction}
encryption.key=${ENCRYPTION_KEY:developmentEncryptionKeyNotForProduction}

# Email Configuration (Console output)
spring.mail.host=localhost
spring.mail.port=1025
spring.mail.username=
spring.mail.password=
spring.mail.properties.mail.smtp.auth=false
spring.mail.properties.mail.smtp.starttls.enable=false
# Email Configuration (Console output for development)
# spring.mail.host=${MAIL_HOST:localhost}
# spring.mail.port=${MAIL_PORT:1025}
# spring.mail.username=${MAIL_USERNAME:}
# spring.mail.password=${MAIL_PASSWORD:}
# spring.mail.properties.mail.smtp.auth=${MAIL_SMTP_AUTH:false}
# spring.mail.properties.mail.smtp.starttls.enable=${MAIL_SMTP_STARTTLS:false}

# Logging Configuration
logging.level.com.example.demo=DEBUG
logging.level.org.springframework.web=DEBUG
logging.level.org.springframework.security=DEBUG
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE
logging.level.org.springframework.cache=DEBUG

# Actuator Configuration
management.endpoints.web.exposure.include=*
management.endpoint.health.show-details=always
management.health.redis.enabled=true
management.health.db.enabled=true

# CORS Configuration (Allow all origins for development)
cors.allowed-origins=http://localhost:3000,http://localhost:5173
cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
cors.allowed-headers=*
cors.allow-credentials=true

# File Storage
file.upload.directory=./uploads/dev
file.temp.directory=./temp/dev
# file.upload.directory=${FILE_UPLOAD_DIR:/app/uploads/dev}
# file.temp.directory=${FILE_TEMP_DIR:/app/temp/dev}
</file>

<file path="application-local.properties">
# Local Development Configuration
# Override database settings for local development

# Database Configuration
spring.datasource.url=jdbc:postgresql://localhost:5432/employee_management
spring.datasource.username=employee_admin
spring.datasource.password=dev_password123

# Redis Configuration (optional - for local development)
spring.data.redis.host=localhost
spring.data.redis.port=6379

# Disable Redis for local development if not available
# spring.data.redis.host=localhost
# spring.data.redis.port=6379

# Flyway Configuration
spring.flyway.enabled=true
spring.flyway.locations=classpath:db/migration
spring.flyway.baseline-on-migrate=true

# Logging
logging.level.com.example.demo=DEBUG
logging.level.org.springframework.security=DEBUG
</file>

<file path="application-prod.properties">
# Production Environment Configuration
# Employee Management System - Production Profile

# ========================================
# SERVER CONFIGURATION
# ========================================
server.port=${SERVER_PORT:8080}
server.servlet.context-path=${CONTEXT_PATH:/api}
server.compression.enabled=true
server.compression.mime-types=text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json
server.compression.min-response-size=1024

# Security Headers
server.error.include-message=never
server.error.include-binding-errors=never
server.error.include-stacktrace=never
server.error.include-exception=false
server.error.whitelabel.enabled=false

# ========================================
# DATABASE CONFIGURATION
# ========================================
# Primary PostgreSQL Database
spring.datasource.url=${DATABASE_URL:jdbc:postgresql://localhost:5432/employee_management}
spring.datasource.username=${DATABASE_USERNAME:employee_admin}
spring.datasource.password=${DATABASE_PASSWORD}
spring.datasource.driver-class-name=org.postgresql.Driver

# Connection Pool Configuration (HikariCP)
spring.datasource.hikari.maximum-pool-size=${DB_POOL_MAX_SIZE:30}
spring.datasource.hikari.minimum-idle=${DB_POOL_MIN_IDLE:10}
spring.datasource.hikari.idle-timeout=${DB_POOL_IDLE_TIMEOUT:600000}
spring.datasource.hikari.connection-timeout=${DB_POOL_CONNECTION_TIMEOUT:30000}
spring.datasource.hikari.max-lifetime=${DB_POOL_MAX_LIFETIME:1800000}
spring.datasource.hikari.leak-detection-threshold=${DB_POOL_LEAK_DETECTION:60000}
spring.datasource.hikari.pool-name=EmployeeManagementPool

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.format_sql=false
spring.jpa.properties.hibernate.use_sql_comments=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.jdbc.batch_size=25
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true

# Flyway Configuration
spring.flyway.enabled=true
spring.flyway.locations=classpath:db/migration
spring.flyway.baseline-on-migrate=true
spring.flyway.validate-on-migrate=true
spring.flyway.out-of-order=false

# ========================================
# REDIS CONFIGURATION
# ========================================
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.password=${REDIS_PASSWORD:}
spring.data.redis.database=${REDIS_DATABASE:0}
spring.data.redis.ssl.enabled=${REDIS_SSL_ENABLED:false}
spring.data.redis.timeout=${REDIS_TIMEOUT:2000ms}

# Redis Connection Pool
spring.data.redis.jedis.pool.max-active=${REDIS_POOL_MAX_ACTIVE:20}
spring.data.redis.jedis.pool.max-idle=${REDIS_POOL_MAX_IDLE:10}
spring.data.redis.jedis.pool.min-idle=${REDIS_POOL_MIN_IDLE:5}
spring.data.redis.jedis.pool.max-wait=${REDIS_POOL_MAX_WAIT:2000ms}

# Cache Configuration
spring.cache.type=redis
spring.cache.redis.time-to-live=${CACHE_TTL:600000}
spring.cache.redis.cache-null-values=false

# ========================================
# SECURITY CONFIGURATION
# ========================================
# JWT Configuration
jwt.secret=${JWT_SECRET}
jwt.expiration=${JWT_EXPIRATION:3600000}
jwt.refresh-expiration=${JWT_REFRESH_EXPIRATION:86400000}
jwt.issuer=${JWT_ISSUER:employee-management-system}

# Encryption Configuration
encryption.key=${ENCRYPTION_KEY}
encryption.algorithm=${ENCRYPTION_ALGORITHM:AES/GCM/NoPadding}

# Session Configuration
spring.session.store-type=redis
spring.session.redis.namespace=employee-management:session
spring.session.timeout=${SESSION_TIMEOUT:1800s}

# Rate Limiting
rate.limit.enabled=${RATE_LIMIT_ENABLED:true}
rate.limit.requests-per-minute=${RATE_LIMIT_RPM:100}

# ========================================
# EMAIL CONFIGURATION
# ========================================
spring.mail.host=${EMAIL_HOST}
spring.mail.port=${EMAIL_PORT:587}
spring.mail.username=${EMAIL_USERNAME}
spring.mail.password=${EMAIL_PASSWORD}
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
spring.mail.properties.mail.smtp.starttls.required=true
spring.mail.properties.mail.smtp.connectiontimeout=${EMAIL_CONNECTION_TIMEOUT:5000}
spring.mail.properties.mail.smtp.timeout=${EMAIL_TIMEOUT:5000}
spring.mail.properties.mail.smtp.writetimeout=${EMAIL_WRITE_TIMEOUT:5000}

# Email Templates
email.template.path=${EMAIL_TEMPLATE_PATH:classpath:/templates/email/}
email.from.address=${EMAIL_FROM_ADDRESS:noreply@company.com}
email.from.name=${EMAIL_FROM_NAME:Employee Management System}

# ========================================
# LOGGING CONFIGURATION
# ========================================
# Root Logging Level
logging.level.root=WARN

# Application Logging
logging.level.com.example.demo=INFO
logging.level.com.example.demo.security=INFO
logging.level.com.example.demo.payroll=INFO

# Framework Logging
logging.level.org.springframework.security=WARN
logging.level.org.springframework.web=WARN
logging.level.org.hibernate.SQL=WARN
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=WARN
logging.level.org.flywaydb=INFO

# File Logging
logging.file.name=${LOG_FILE_PATH:logs/employee-management.log}
logging.file.max-size=${LOG_FILE_MAX_SIZE:50MB}
logging.file.max-history=${LOG_FILE_MAX_HISTORY:30}
logging.file.total-size-cap=${LOG_FILE_TOTAL_SIZE:1GB}

# Logging Pattern
logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{traceId},%X{spanId}] %logger{36} - %msg%n
logging.pattern.console=%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n

# ========================================
# MONITORING & ACTUATOR CONFIGURATION
# ========================================
# Actuator Endpoints
management.endpoints.web.exposure.include=health,info,metrics,prometheus,loggers
management.endpoints.web.base-path=/actuator
management.endpoint.health.show-details=when-authorized
management.endpoint.health.show-components=always
management.endpoint.info.enabled=true
management.endpoint.metrics.enabled=true
management.endpoint.prometheus.enabled=true

# Health Checks
management.health.redis.enabled=true
management.health.db.enabled=true
management.health.mail.enabled=true
management.health.diskspace.enabled=true

# Metrics
management.metrics.export.prometheus.enabled=true
management.metrics.distribution.percentiles-histogram.http.server.requests=true
management.metrics.distribution.percentiles.http.server.requests=0.5,0.9,0.95,0.99
management.metrics.tags.application=employee-management-system
management.metrics.tags.environment=${ENVIRONMENT:production}

# Info Endpoint
info.app.name=Employee Management System
info.app.version=@project.version@
info.app.description=@project.description@
info.app.encoding=@project.build.sourceEncoding@
info.java.version=@java.version@

# ========================================
# CORS CONFIGURATION
# ========================================
cors.allowed-origins=${CORS_ALLOWED_ORIGINS:https://yourdomain.com}
cors.allowed-methods=${CORS_ALLOWED_METHODS:GET,POST,PUT,DELETE,OPTIONS}
cors.allowed-headers=${CORS_ALLOWED_HEADERS:Authorization,Content-Type,X-Requested-With,X-CSRF-TOKEN}
cors.allow-credentials=${CORS_ALLOW_CREDENTIALS:true}
cors.max-age=${CORS_MAX_AGE:3600}

# ========================================
# FILE STORAGE CONFIGURATION
# ========================================
file.upload.directory=${FILE_UPLOAD_DIR:/var/app/uploads}
file.temp.directory=${FILE_TEMP_DIR:/var/app/temp}
file.max-size=${FILE_MAX_SIZE:10MB}
file.allowed-types=${FILE_ALLOWED_TYPES:image/jpeg,image/png,application/pdf,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet}

# ========================================
# SSL/TLS CONFIGURATION
# ========================================
server.ssl.enabled=${SSL_ENABLED:false}
server.ssl.key-store=${SSL_KEYSTORE:}
server.ssl.key-store-password=${SSL_KEYSTORE_PASSWORD:}
server.ssl.key-store-type=${SSL_KEYSTORE_TYPE:PKCS12}
server.ssl.key-alias=${SSL_KEY_ALIAS:}
server.ssl.protocol=${SSL_PROTOCOL:TLS}
server.ssl.enabled-protocols=${SSL_ENABLED_PROTOCOLS:TLSv1.2,TLSv1.3}

# ========================================
# ASYNC CONFIGURATION
# ========================================
async.core-pool-size=${ASYNC_CORE_POOL_SIZE:5}
async.max-pool-size=${ASYNC_MAX_POOL_SIZE:20}
async.queue-capacity=${ASYNC_QUEUE_CAPACITY:100}
async.thread-name-prefix=async-executor-

# ========================================
# WEBSOCKET CONFIGURATION
# ========================================
websocket.allowed-origins=${WEBSOCKET_ALLOWED_ORIGINS:https://yourdomain.com}
websocket.message-size-limit=${WEBSOCKET_MESSAGE_SIZE_LIMIT:8192}
websocket.send-buffer-size=${WEBSOCKET_SEND_BUFFER_SIZE:8192}
websocket.send-time-limit=${WEBSOCKET_SEND_TIME_LIMIT:10000}

# ========================================
# BUSINESS CONFIGURATION
# ========================================
# Payroll Configuration
payroll.calculation.enabled=${PAYROLL_CALCULATION_ENABLED:true}
payroll.audit.enabled=${PAYROLL_AUDIT_ENABLED:true}

# Employee Configuration
employee.import.batch-size=${EMPLOYEE_IMPORT_BATCH_SIZE:100}
employee.export.max-records=${EMPLOYEE_EXPORT_MAX_RECORDS:10000}

# Notification Configuration
notification.cleanup.enabled=${NOTIFICATION_CLEANUP_ENABLED:true}
notification.cleanup.days=${NOTIFICATION_CLEANUP_DAYS:90}
</file>

<file path="application-staging.properties">
# Staging Environment Configuration
# Employee Management System - Staging Profile

# ========================================
# SERVER CONFIGURATION
# ========================================
server.port=${SERVER_PORT:8080}
server.servlet.context-path=${CONTEXT_PATH:/api}
server.compression.enabled=true

# Error Handling (More verbose than production for debugging)
server.error.include-message=on_param
server.error.include-binding-errors=on_param
server.error.include-stacktrace=on_param
server.error.include-exception=false

# ========================================
# DATABASE CONFIGURATION
# ========================================
spring.datasource.url=${DATABASE_URL:jdbc:postgresql://localhost:5432/employee_management_staging}
spring.datasource.username=${DATABASE_USERNAME:employee_admin}
spring.datasource.password=${DATABASE_PASSWORD}
spring.datasource.driver-class-name=org.postgresql.Driver

# Connection Pool (Smaller than production)
spring.datasource.hikari.maximum-pool-size=15
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.max-lifetime=1200000
spring.datasource.hikari.leak-detection-threshold=30000

# JPA Configuration (More verbose for debugging)
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.show-sql=${JPA_SHOW_SQL:false}
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.use_sql_comments=true
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

# ========================================
# REDIS CONFIGURATION
# ========================================
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.password=${REDIS_PASSWORD:}
spring.data.redis.database=1
spring.data.redis.timeout=2000ms

# ========================================
# SECURITY CONFIGURATION
# ========================================
jwt.secret=${JWT_SECRET}
jwt.expiration=7200000
jwt.refresh-expiration=172800000
encryption.key=${ENCRYPTION_KEY}

# ========================================
# EMAIL CONFIGURATION
# ========================================
spring.mail.host=${EMAIL_HOST:localhost}
spring.mail.port=${EMAIL_PORT:1025}
spring.mail.username=${EMAIL_USERNAME:}
spring.mail.password=${EMAIL_PASSWORD:}
spring.mail.properties.mail.smtp.auth=false
spring.mail.properties.mail.smtp.starttls.enable=false

# ========================================
# LOGGING CONFIGURATION
# ========================================
logging.level.root=INFO
logging.level.com.example.demo=DEBUG
logging.level.org.springframework.security=DEBUG
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE

logging.file.name=logs/employee-management-staging.log
logging.file.max-size=20MB
logging.file.max-history=10

# ========================================
# MONITORING CONFIGURATION
# ========================================
management.endpoints.web.exposure.include=health,info,metrics,loggers,env,configprops
management.endpoint.health.show-details=always
management.endpoint.env.show-values=when-authorized

# ========================================
# CORS CONFIGURATION
# ========================================
cors.allowed-origins=${CORS_ALLOWED_ORIGINS:http://localhost:3000,https://staging.yourdomain.com}
cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
cors.allowed-headers=Authorization,Content-Type,X-Requested-With
cors.allow-credentials=true

# ========================================
# FILE STORAGE CONFIGURATION
# ========================================
file.upload.directory=${FILE_UPLOAD_DIR:/tmp/staging/uploads}
file.temp.directory=${FILE_TEMP_DIR:/tmp/staging/temp}
file.max-size=5MB
</file>

<file path="application.properties">
# Employee Management System - Main Configuration
# Spring Boot 3.5.4 with Java 24

# Server Configuration
server.port=8080
server.servlet.context-path=/api
server.error.include-message=on_param
server.error.include-binding-errors=on_param

# Application Information
spring.application.name=Employee Management System
info.app.name=Employee Management System
info.app.description=Spring Boot Employee Management System with PostgreSQL and Redis
info.app.version=1.0.0

# Profile Configuration
# spring.profiles.active=dev
spring.profiles.active=hybrid

# PostgreSQL Database Configuration
# spring.datasource.url=jdbc:postgresql://localhost:5432/employee_management
# spring.datasource.username=employee_admin
# spring.datasource.password=dev_password123
spring.datasource.url=jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:employee_management}
spring.datasource.username=${DB_USERNAME:employee_admin}
spring.datasource.password=${DB_PASSWORD:dev_password123}
spring.datasource.driver-class-name=org.postgresql.Driver

# HikariCP Connection Pool Configuration
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=5
spring.datasource.hikari.idle-timeout=300000
spring.datasource.hikari.connection-timeout=20000
spring.datasource.hikari.max-lifetime=1200000
spring.datasource.hikari.pool-name=EmployeeManagementPool

# JPA/Hibernate Configuration
spring.jpa.hibernate.ddl-auto=validate
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.use_sql_comments=true
spring.jpa.properties.hibernate.jdbc.batch_size=20
spring.jpa.properties.hibernate.order_inserts=true
spring.jpa.properties.hibernate.order_updates=true
spring.jpa.properties.hibernate.jdbc.batch_versioned_data=true

# Flyway Configuration
spring.flyway.enabled=true
spring.flyway.locations=classpath:db/migration
spring.flyway.baseline-on-migrate=true
spring.flyway.validate-on-migrate=true
spring.flyway.out-of-order=false

# Redis Configuration
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.database=${REDIS_DB:0}
spring.data.redis.password=${REDIS_PASSWORD:}
spring.data.redis.timeout=2000ms
spring.data.redis.lettuce.pool.max-active=8
spring.data.redis.lettuce.pool.max-idle=8
spring.data.redis.lettuce.pool.min-idle=0
spring.data.redis.lettuce.pool.max-wait=-1ms

# Cache Configuration
spring.cache.type=redis
spring.cache.redis.time-to-live=600000
spring.cache.redis.cache-null-values=false

# Security Configuration
# JWT Configuration (use environment variables in production)
jwt.secret=${JWT_SECRET:mySecretKeyForDevelopmentOnlyChangeInProduction}
jwt.expiration=86400000
jwt.refresh-expiration=604800000

# Encryption Configuration (use environment variables in production)
encryption.key=${ENCRYPTION_KEY:myEncryptionKeyForDevelopmentOnly}

# Email Configuration
spring.mail.host=localhost
spring.mail.port=587
spring.mail.username=${EMAIL_USERNAME:}
spring.mail.password=${EMAIL_PASSWORD:}
spring.mail.properties.mail.smtp.auth=true
spring.mail.properties.mail.smtp.starttls.enable=true
spring.mail.properties.mail.smtp.starttls.required=true

# File Upload Configuration
spring.servlet.multipart.enabled=true
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB

# Async Configuration
spring.task.execution.pool.core-size=5
spring.task.execution.pool.max-size=20
spring.task.execution.pool.queue-capacity=100
spring.task.execution.thread-name-prefix=async-

# Actuator Configuration
management.endpoints.web.exposure.include=health,info,metrics,prometheus
management.endpoint.health.show-details=when_authorized
management.metrics.export.prometheus.enabled=true

# Logging Configuration
logging.level.com.example.demo=INFO
logging.level.org.springframework.security=DEBUG
logging.level.org.hibernate.SQL=DEBUG
logging.level.org.hibernate.type.descriptor.sql.BasicBinder=TRACE
logging.pattern.console=%d{yyyy-MM-dd HH:mm:ss} - %msg%n
logging.pattern.file=%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n

# Jackson Configuration
spring.jackson.serialization.write-dates-as-timestamps=false
spring.jackson.time-zone=UTC
spring.jackson.date-format=yyyy-MM-dd HH:mm:ss

# WebSocket Configuration
app.websocket.allowed-origins=http://localhost:3000,http://localhost:5173,http://localhost:8080
app.websocket.heartbeat.client=10000
app.websocket.heartbeat.server=10000

# CSRF Configuration
app.csrf.enabled=true
app.csrf.cookie.name=XSRF-TOKEN
app.csrf.header.name=X-XSRF-TOKEN
app.csrf.parameter.name=_csrf
app.csrf.cookie.http-only=false
app.csrf.cookie.secure=false
app.csrf.cookie.same-site=Lax
</file>

<file path="db/migration/.gitkeep">
# This file ensures the db/migration directory is tracked by Git
# Flyway migration scripts will be placed in this directory
</file>

<file path="db/migration/V0__Initial_baseline.sql">
-- Initial baseline migration for Employee Management System
-- This migration establishes the baseline for the database schema
-- Version: V0__Initial_baseline.sql
-- Description: Creates the initial database structure baseline

-- Enable UUID extension for PostgreSQL
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create schema for application tables (optional, using public schema by default)
-- CREATE SCHEMA IF NOT EXISTS employee_management;

-- Create audit trigger function for automatic timestamp updates
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Create function for generating employee numbers
CREATE OR REPLACE FUNCTION generate_employee_number()
RETURNS TEXT AS $$
DECLARE
    next_number INTEGER;
    employee_number TEXT;
BEGIN
    -- Get the next sequence number
    SELECT COALESCE(MAX(CAST(SUBSTRING(employee_number FROM 4) AS INTEGER)), 0) + 1
    INTO next_number
    FROM employees
    WHERE employee_number ~ '^EMP[0-9]{6}$';
    
    -- Format as EMP followed by 6 digits
    employee_number := 'EMP' || LPAD(next_number::TEXT, 6, '0');
    
    RETURN employee_number;
END;
$$ LANGUAGE plpgsql;

-- Create function for generating department codes
CREATE OR REPLACE FUNCTION generate_department_code()
RETURNS TEXT AS $$
DECLARE
    next_number INTEGER;
    department_code TEXT;
BEGIN
    -- Get the next sequence number
    SELECT COALESCE(MAX(CAST(SUBSTRING(code FROM 5) AS INTEGER)), 0) + 1
    INTO next_number
    FROM departments
    WHERE code ~ '^DEPT[0-9]{4}$';
    
    -- Format as DEPT followed by 4 digits
    department_code := 'DEPT' || LPAD(next_number::TEXT, 4, '0');
    
    RETURN department_code;
END;
$$ LANGUAGE plpgsql;

-- Create function for generating position codes
CREATE OR REPLACE FUNCTION generate_position_code()
RETURNS TEXT AS $$
DECLARE
    next_number INTEGER;
    position_code TEXT;
BEGIN
    -- Get the next sequence number
    SELECT COALESCE(MAX(CAST(SUBSTRING(code FROM 4) AS INTEGER)), 0) + 1
    INTO next_number
    FROM positions
    WHERE code ~ '^POS[0-9]{4}$';
    
    -- Format as POS followed by 4 digits
    position_code := 'POS' || LPAD(next_number::TEXT, 4, '0');
    
    RETURN position_code;
END;
$$ LANGUAGE plpgsql;

-- Create indexes for common query patterns (will be used by future migrations)
-- These are placeholder comments for the actual table creation in subsequent migrations

-- Baseline migration completed
-- Next migrations will create the actual table structures:
-- V1__Create_security_tables.sql - User, Role, Resource tables
-- V2__Create_departments_table.sql - Department hierarchy
-- V3__Create_positions_table.sql - Position management
-- V4__Create_employees_table.sql - Employee data
-- V5__Create_email_tables.sql - Email templates and logs
-- V6__Create_notification_tables.sql - Notification system
-- V7__Create_payroll_tables.sql - Payroll management

COMMENT ON EXTENSION "uuid-ossp" IS 'UUID generation functions for primary keys';
COMMENT ON FUNCTION update_updated_at_column() IS 'Trigger function to automatically update updated_at timestamps';
COMMENT ON FUNCTION generate_employee_number() IS 'Generates sequential employee numbers in format EMP######';
COMMENT ON FUNCTION generate_department_code() IS 'Generates sequential department codes in format DEPT####';
COMMENT ON FUNCTION generate_position_code() IS 'Generates sequential position codes in format POS####';
</file>

<file path="db/migration/V1__Create_security_tables.sql">
-- Create users table
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    username VARCHAR(50) NOT NULL,
    password VARCHAR(255) NOT NULL,
    email VARCHAR(100) NOT NULL,
    first_name VARCHAR(50),
    last_name VARCHAR(50),
    enabled BOOLEAN NOT NULL DEFAULT true,
    last_login TIMESTAMP,
    login_attempts INTEGER NOT NULL DEFAULT 0,
    account_locked BOOLEAN NOT NULL DEFAULT false,
    account_locked_until TIMESTAMP,
    password_expired BOOLEAN NOT NULL DEFAULT false,
    password_change_required BOOLEAN NOT NULL DEFAULT false,
    password_changed_at TIMESTAMP,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT,
    
    CONSTRAINT uk_user_username UNIQUE (username),
    CONSTRAINT uk_user_email UNIQUE (email)
);

-- Create indexes for users table
CREATE INDEX idx_user_username ON users (username);
CREATE INDEX idx_user_email ON users (email);
CREATE INDEX idx_user_enabled ON users (enabled);
CREATE INDEX idx_user_account_locked ON users (account_locked);

-- Create roles table
CREATE TABLE roles (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(50) NOT NULL UNIQUE,
    description VARCHAR(255),
    active BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT
);

-- Create indexes for roles table
CREATE INDEX idx_role_name ON roles (name);
CREATE INDEX idx_role_active ON roles (active);

-- Create resources table
CREATE TABLE resources (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    url VARCHAR(255) NOT NULL,
    method VARCHAR(10) NOT NULL,
    description VARCHAR(255),
    category VARCHAR(50) NOT NULL,
    active BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT,
    
    CONSTRAINT uk_resource_url_method UNIQUE (url, method)
);

-- Create indexes for resources table
CREATE INDEX idx_resource_url ON resources (url);
CREATE INDEX idx_resource_method ON resources (method);
CREATE INDEX idx_resource_category ON resources (category);
CREATE INDEX idx_resource_active ON resources (active);

-- Create user_roles junction table
CREATE TABLE user_roles (
    user_id BIGINT NOT NULL,
    role_id BIGINT NOT NULL,
    
    PRIMARY KEY (user_id, role_id),
    CONSTRAINT fk_user_roles_user FOREIGN KEY (user_id) REFERENCES users (id) ON DELETE CASCADE,
    CONSTRAINT fk_user_roles_role FOREIGN KEY (role_id) REFERENCES roles (id) ON DELETE CASCADE
);

-- Create role_resources junction table
CREATE TABLE role_resources (
    role_id BIGINT NOT NULL,
    resource_id BIGINT NOT NULL,
    
    PRIMARY KEY (role_id, resource_id),
    CONSTRAINT fk_role_resources_role FOREIGN KEY (role_id) REFERENCES roles (id) ON DELETE CASCADE,
    CONSTRAINT fk_role_resources_resource FOREIGN KEY (resource_id) REFERENCES resources (id) ON DELETE CASCADE
);

-- Insert default system roles
INSERT INTO roles (name, description, active, created_at) VALUES
('ADMIN', 'System Administrator with full access', true, CURRENT_TIMESTAMP),
('HR_MANAGER', 'HR Manager with employee management access', true, CURRENT_TIMESTAMP),
('EMPLOYEE', 'Regular employee with limited access', true, CURRENT_TIMESTAMP),
('DEPARTMENT_MANAGER', 'Department Manager with team management access', true, CURRENT_TIMESTAMP);

-- Insert default system resources
INSERT INTO resources (name, url, method, description, category, active, created_at) VALUES
-- User Management
('User List', '/api/users', 'GET', 'View user list', 'USER_MANAGEMENT', true, CURRENT_TIMESTAMP),
('User Create', '/api/users', 'POST', 'Create new user', 'USER_MANAGEMENT', true, CURRENT_TIMESTAMP),
('User Update', '/api/users/*', 'PUT', 'Update user information', 'USER_MANAGEMENT', true, CURRENT_TIMESTAMP),
('User Delete', '/api/users/*', 'DELETE', 'Delete user', 'USER_MANAGEMENT', true, CURRENT_TIMESTAMP),

-- Role Management
('Role List', '/api/roles', 'GET', 'View role list', 'ROLE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Role Create', '/api/roles', 'POST', 'Create new role', 'ROLE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Role Update', '/api/roles/*', 'PUT', 'Update role information', 'ROLE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Role Delete', '/api/roles/*', 'DELETE', 'Delete role', 'ROLE_MANAGEMENT', true, CURRENT_TIMESTAMP),

-- Employee Management
('Employee List', '/api/employees', 'GET', 'View employee list', 'EMPLOYEE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Employee Create', '/api/employees', 'POST', 'Create new employee', 'EMPLOYEE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Employee Update', '/api/employees/*', 'PUT', 'Update employee information', 'EMPLOYEE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Employee Delete', '/api/employees/*', 'DELETE', 'Delete employee', 'EMPLOYEE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Employee Import', '/api/employees/import', 'POST', 'Import employees from Excel', 'EMPLOYEE_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Employee Export', '/api/employees/export', 'GET', 'Export employees to Excel', 'EMPLOYEE_MANAGEMENT', true, CURRENT_TIMESTAMP),

-- Department Management
('Department List', '/api/departments', 'GET', 'View department list', 'DEPARTMENT_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Department Create', '/api/departments', 'POST', 'Create new department', 'DEPARTMENT_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Department Update', '/api/departments/*', 'PUT', 'Update department information', 'DEPARTMENT_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Department Delete', '/api/departments/*', 'DELETE', 'Delete department', 'DEPARTMENT_MANAGEMENT', true, CURRENT_TIMESTAMP),

-- Position Management
('Position List', '/api/positions', 'GET', 'View position list', 'POSITION_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Position Create', '/api/positions', 'POST', 'Create new position', 'POSITION_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Position Update', '/api/positions/*', 'PUT', 'Update position information', 'POSITION_MANAGEMENT', true, CURRENT_TIMESTAMP),
('Position Delete', '/api/positions/*', 'DELETE', 'Delete position', 'POSITION_MANAGEMENT', true, CURRENT_TIMESTAMP);

-- Assign resources to ADMIN role (full access)
INSERT INTO role_resources (role_id, resource_id)
SELECT r.id, res.id
FROM roles r
CROSS JOIN resources res
WHERE r.name = 'ADMIN';

-- Assign employee management resources to HR_MANAGER role
INSERT INTO role_resources (role_id, resource_id)
SELECT r.id, res.id
FROM roles r
CROSS JOIN resources res
WHERE r.name = 'HR_MANAGER'
AND res.category IN ('EMPLOYEE_MANAGEMENT', 'DEPARTMENT_MANAGEMENT', 'POSITION_MANAGEMENT');

-- Assign limited resources to EMPLOYEE role
INSERT INTO role_resources (role_id, resource_id)
SELECT r.id, res.id
FROM roles r
CROSS JOIN resources res
WHERE r.name = 'EMPLOYEE'
AND res.method = 'GET'
AND res.category IN ('EMPLOYEE_MANAGEMENT', 'DEPARTMENT_MANAGEMENT');

-- Assign department and employee management to DEPARTMENT_MANAGER role
INSERT INTO role_resources (role_id, resource_id)
SELECT r.id, res.id
FROM roles r
CROSS JOIN resources res
WHERE r.name = 'DEPARTMENT_MANAGER'
AND res.category IN ('EMPLOYEE_MANAGEMENT', 'DEPARTMENT_MANAGEMENT');

-- Create default admin user (password: admin123 - should be changed in production)
-- Note: This is a BCrypt hash of 'admin123'
INSERT INTO users (username, password, email, first_name, last_name, enabled, created_at)
VALUES ('admin', '$2a$10$N.zmdr9k7uOCQb376NoUnuTJ8iAt6Z5EHsM8lE9lBOsl7iKTVMFvK', 'admin@company.com', 'System', 'Administrator', true, CURRENT_TIMESTAMP);

-- Assign ADMIN role to default admin user
INSERT INTO user_roles (user_id, role_id)
SELECT u.id, r.id
FROM users u
CROSS JOIN roles r
WHERE u.username = 'admin' AND r.name = 'ADMIN';
</file>

<file path="db/migration/V2__Create_departments_table.sql">
-- Create departments table with hierarchical structure
CREATE TABLE departments (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    code VARCHAR(20) NOT NULL UNIQUE,
    description VARCHAR(500),
    location VARCHAR(255),
    parent_id BIGINT,
    dep_path VARCHAR(500),
    is_parent BOOLEAN NOT NULL DEFAULT FALSE,
    enabled BOOLEAN NOT NULL DEFAULT TRUE,
    level INTEGER DEFAULT 0,
    sort_order INTEGER DEFAULT 0,
    manager_id BIGINT,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT,
    
    -- Self-referencing foreign key for hierarchy
    CONSTRAINT fk_department_parent FOREIGN KEY (parent_id) REFERENCES departments(id) ON DELETE RESTRICT,
    
    -- Check constraints
    CONSTRAINT chk_department_level CHECK (level >= 0),
    CONSTRAINT chk_department_sort_order CHECK (sort_order >= 0),
    CONSTRAINT chk_department_name_not_empty CHECK (LENGTH(TRIM(name)) > 0),
    CONSTRAINT chk_department_code_not_empty CHECK (LENGTH(TRIM(code)) > 0)
);

-- Create indexes for performance optimization
CREATE INDEX idx_department_name ON departments(name);
CREATE INDEX idx_department_code ON departments(code);
CREATE INDEX idx_department_parent_id ON departments(parent_id);
CREATE INDEX idx_department_dep_path ON departments(dep_path);
CREATE INDEX idx_department_enabled ON departments(enabled);
CREATE INDEX idx_department_manager_id ON departments(manager_id);
CREATE INDEX idx_department_level ON departments(level);
CREATE INDEX idx_department_sort_order ON departments(sort_order);

-- Composite indexes for common queries
CREATE INDEX idx_department_parent_sort ON departments(parent_id, sort_order);
CREATE INDEX idx_department_enabled_path ON departments(enabled, dep_path);

-- Insert default root departments
INSERT INTO departments (name, code, description, dep_path, is_parent, level, sort_order) VALUES
('Company', 'COMP', 'Root company department', '/COMP', TRUE, 0, 1),
('Human Resources', 'HR', 'Human Resources Department', '/COMP/HR', FALSE, 1, 1),
('Information Technology', 'IT', 'Information Technology Department', '/COMP/IT', FALSE, 1, 2),
('Finance', 'FIN', 'Finance Department', '/COMP/FIN', FALSE, 1, 3),
('Operations', 'OPS', 'Operations Department', '/COMP/OPS', FALSE, 1, 4);

-- Update parent relationships
UPDATE departments SET parent_id = (SELECT id FROM departments WHERE code = 'COMP') 
WHERE code IN ('HR', 'IT', 'FIN', 'OPS');

-- Update is_parent flag for company
UPDATE departments SET is_parent = TRUE WHERE code = 'COMP';

-- Create trigger to automatically update dep_path and level
CREATE OR REPLACE FUNCTION update_department_path()
RETURNS TRIGGER AS $$
DECLARE
    parent_path VARCHAR(500);
    parent_level INTEGER;
BEGIN
    IF NEW.parent_id IS NULL THEN
        -- Root department
        NEW.dep_path := '/' || NEW.code;
        NEW.level := 0;
        NEW.is_parent := CASE WHEN EXISTS(SELECT 1 FROM departments WHERE parent_id = NEW.id) THEN TRUE ELSE FALSE END;
    ELSE
        -- Child department
        SELECT dep_path, level INTO parent_path, parent_level
        FROM departments WHERE id = NEW.parent_id;
        
        IF parent_path IS NULL THEN
            RAISE EXCEPTION 'Parent department not found';
        END IF;
        
        NEW.dep_path := parent_path || '/' || NEW.code;
        NEW.level := parent_level + 1;
        
        -- Update parent's is_parent flag
        UPDATE departments SET is_parent = TRUE WHERE id = NEW.parent_id;
    END IF;
    
    NEW.updated_at := CURRENT_TIMESTAMP;
    
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create trigger
CREATE TRIGGER trigger_update_department_path
    BEFORE INSERT OR UPDATE ON departments
    FOR EACH ROW
    EXECUTE FUNCTION update_department_path();

-- Create function to update is_parent flag when departments are deleted
CREATE OR REPLACE FUNCTION update_parent_flag_on_delete()
RETURNS TRIGGER AS $$
BEGIN
    -- Update parent's is_parent flag if no more children exist
    IF OLD.parent_id IS NOT NULL THEN
        UPDATE departments 
        SET is_parent = CASE WHEN EXISTS(SELECT 1 FROM departments WHERE parent_id = OLD.parent_id AND id != OLD.id) THEN TRUE ELSE FALSE END
        WHERE id = OLD.parent_id;
    END IF;
    
    RETURN OLD;
END;
$$ LANGUAGE plpgsql;

-- Create delete trigger
CREATE TRIGGER trigger_update_parent_flag_on_delete
    AFTER DELETE ON departments
    FOR EACH ROW
    EXECUTE FUNCTION update_parent_flag_on_delete();

-- Add comments for documentation
COMMENT ON TABLE departments IS 'Hierarchical department structure with path-based organization';
COMMENT ON COLUMN departments.dep_path IS 'Full path from root to this department (e.g., /COMP/IT/DEV)';
COMMENT ON COLUMN departments.is_parent IS 'Flag indicating if this department has child departments';
COMMENT ON COLUMN departments.level IS 'Hierarchy level (0 for root departments)';
COMMENT ON COLUMN departments.sort_order IS 'Sort order within the same parent level';
COMMENT ON COLUMN departments.manager_id IS 'Employee ID of the department manager';
</file>

<file path="db/migration/V3__Create_positions_table.sql">
-- Create positions table for job position management
CREATE TABLE positions (
    id BIGSERIAL PRIMARY KEY,
    job_title VARCHAR(100) NOT NULL,
    professional_title VARCHAR(100),
    code VARCHAR(20) NOT NULL UNIQUE,
    description TEXT,
    requirements TEXT,
    responsibilities TEXT,
    category VARCHAR(20) NOT NULL DEFAULT 'TECHNICAL',
    salary_grade VARCHAR(10),
    department_id BIGINT NOT NULL,
    level VARCHAR(20) NOT NULL DEFAULT 'JUNIOR',
    enabled BOOLEAN NOT NULL DEFAULT true,
    min_salary DECIMAL(12,2),
    max_salary DECIMAL(12,2),
    required_skills TEXT,
    required_education VARCHAR(500),
    required_experience INTEGER,
    benefits TEXT,
    work_location VARCHAR(255),
    employment_type VARCHAR(20) NOT NULL DEFAULT 'FULL_TIME',
    is_managerial BOOLEAN NOT NULL DEFAULT false,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT,
    
    -- Foreign key constraint to departments table
    CONSTRAINT fk_position_department FOREIGN KEY (department_id) REFERENCES departments(id) ON DELETE RESTRICT
);

-- Create indexes for performance optimization
CREATE INDEX idx_position_job_title ON positions(job_title);
CREATE INDEX idx_position_code ON positions(code);
CREATE INDEX idx_position_department_id ON positions(department_id);
CREATE INDEX idx_position_level ON positions(level);
CREATE INDEX idx_position_enabled ON positions(enabled);
CREATE INDEX idx_position_category ON positions(category);

-- Add check constraints for enum values
ALTER TABLE positions ADD CONSTRAINT chk_position_category 
    CHECK (category IN ('TECHNICAL', 'MANAGEMENT', 'ADMINISTRATIVE', 'SALES', 'HR', 'FINANCE', 'MARKETING', 'OPERATIONS', 'SUPPORT', 'OTHER'));

ALTER TABLE positions ADD CONSTRAINT chk_position_level 
    CHECK (level IN ('JUNIOR', 'MID', 'SENIOR', 'LEAD', 'MANAGER', 'DIRECTOR', 'VP', 'EXECUTIVE'));

ALTER TABLE positions ADD CONSTRAINT chk_employment_type 
    CHECK (employment_type IN ('FULL_TIME', 'PART_TIME', 'CONTRACT', 'INTERNSHIP', 'TEMPORARY'));

-- Add check constraint for salary range
ALTER TABLE positions ADD CONSTRAINT chk_salary_range 
    CHECK (min_salary IS NULL OR max_salary IS NULL OR min_salary <= max_salary);

-- Add comments for documentation
COMMENT ON TABLE positions IS 'Job positions and titles within the organization';
COMMENT ON COLUMN positions.job_title IS 'The official job title for the position';
COMMENT ON COLUMN positions.professional_title IS 'Professional or industry-standard title';
COMMENT ON COLUMN positions.code IS 'Unique position code for identification';
COMMENT ON COLUMN positions.department_id IS 'Department where this position belongs';
COMMENT ON COLUMN positions.level IS 'Hierarchical level of the position';
COMMENT ON COLUMN positions.category IS 'Functional category of the position';
COMMENT ON COLUMN positions.employment_type IS 'Type of employment (full-time, part-time, etc.)';
COMMENT ON COLUMN positions.is_managerial IS 'Whether this position has management responsibilities';
</file>

<file path="db/migration/V4__Create_employees_table.sql">
-- Create employees table
CREATE TABLE employees (
    id BIGSERIAL PRIMARY KEY,
    employee_number VARCHAR(20) NOT NULL UNIQUE,
    first_name VARCHAR(50) NOT NULL,
    last_name VARCHAR(50) NOT NULL,
    email VARCHAR(100) NOT NULL UNIQUE,
    phone VARCHAR(20),
    mobile_phone VARCHAR(20),
    address VARCHAR(255),
    city VARCHAR(100),
    state VARCHAR(100),
    zip_code VARCHAR(20),
    country VARCHAR(100),
    date_of_birth_encrypted TEXT, -- Encrypted field
    gender VARCHAR(20),
    marital_status VARCHAR(20),
    nationality VARCHAR(50),
    department_id BIGINT NOT NULL,
    position_id BIGINT,
    manager_id BIGINT,
    hire_date DATE NOT NULL,
    termination_date DATE,
    status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE',
    employment_type VARCHAR(20) NOT NULL DEFAULT 'FULL_TIME',
    pay_type VARCHAR(10) NOT NULL DEFAULT 'SALARY',
    salary DECIMAL(12,2),
    hourly_rate DECIMAL(8,2),
    bank_account_encrypted TEXT, -- Encrypted field
    tax_id_encrypted TEXT, -- Encrypted field
    enabled BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT,
    
    -- Foreign key constraints
    CONSTRAINT fk_employee_department FOREIGN KEY (department_id) REFERENCES departments(id),
    CONSTRAINT fk_employee_manager FOREIGN KEY (manager_id) REFERENCES employees(id),
    
    -- Check constraints
    CONSTRAINT chk_employee_status CHECK (status IN ('ACTIVE', 'INACTIVE', 'TERMINATED', 'ON_LEAVE', 'PROBATION', 'SUSPENDED')),
    CONSTRAINT chk_employment_type CHECK (employment_type IN ('FULL_TIME', 'PART_TIME', 'CONTRACT', 'TEMPORARY', 'INTERN', 'CONSULTANT')),
    CONSTRAINT chk_pay_type CHECK (pay_type IN ('SALARY', 'HOURLY')),
    CONSTRAINT chk_gender CHECK (gender IN ('MALE', 'FEMALE', 'OTHER', 'PREFER_NOT_TO_SAY')),
    CONSTRAINT chk_marital_status CHECK (marital_status IN ('SINGLE', 'MARRIED', 'DIVORCED', 'WIDOWED', 'SEPARATED', 'DOMESTIC_PARTNERSHIP')),
    CONSTRAINT chk_salary_positive CHECK (salary IS NULL OR salary >= 0),
    CONSTRAINT chk_hourly_rate_positive CHECK (hourly_rate IS NULL OR hourly_rate >= 0),
    CONSTRAINT chk_hire_date_not_future CHECK (hire_date <= CURRENT_DATE),
    CONSTRAINT chk_termination_after_hire CHECK (termination_date IS NULL OR termination_date >= hire_date)
);

-- Create indexes for performance
CREATE INDEX idx_employee_number ON employees(employee_number);
CREATE INDEX idx_employee_email ON employees(email);
CREATE INDEX idx_employee_department_id ON employees(department_id);
CREATE INDEX idx_employee_position_id ON employees(position_id);
CREATE INDEX idx_employee_status ON employees(status);
CREATE INDEX idx_employee_last_name ON employees(last_name);
CREATE INDEX idx_employee_hire_date ON employees(hire_date);
CREATE INDEX idx_employee_manager_id ON employees(manager_id);

-- Add comments
COMMENT ON TABLE employees IS 'Employee information with comprehensive fields and audit trail';
COMMENT ON COLUMN employees.employee_number IS 'Unique employee identifier';
COMMENT ON COLUMN employees.date_of_birth_encrypted IS 'Encrypted date of birth for privacy';
COMMENT ON COLUMN employees.bank_account_encrypted IS 'Encrypted bank account information';
COMMENT ON COLUMN employees.tax_id_encrypted IS 'Encrypted tax identification number';
COMMENT ON COLUMN employees.enabled IS 'Soft delete flag - false means employee is disabled';
</file>

<file path="db/migration/V5__Create_email_tables.sql">
-- Create email templates table
CREATE TABLE email_templates (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    code VARCHAR(50) NOT NULL UNIQUE,
    subject VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    template_type VARCHAR(20) NOT NULL CHECK (template_type IN ('HTML', 'TEXT', 'MIXED')),
    category VARCHAR(50) CHECK (category IN ('WELCOME', 'NOTIFICATION', 'REMINDER', 'MARKETING', 'PASSWORD_RESET')),
    description VARCHAR(500),
    variables TEXT, -- JSON string of available template variables
    is_default BOOLEAN NOT NULL DEFAULT FALSE,
    enabled BOOLEAN NOT NULL DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE,
    created_by BIGINT,
    updated_by BIGINT
);

-- Create indexes for email_templates
CREATE UNIQUE INDEX idx_emailtemplate_code ON email_templates(code);
CREATE INDEX idx_emailtemplate_category ON email_templates(category);
CREATE INDEX idx_emailtemplate_enabled ON email_templates(enabled);
CREATE INDEX idx_emailtemplate_created_by ON email_templates(created_by);

-- Create email logs table
CREATE TABLE email_logs (
    id BIGSERIAL PRIMARY KEY,
    to_email VARCHAR(255) NOT NULL,
    cc_emails VARCHAR(1000), -- Comma-separated CC emails
    bcc_emails VARCHAR(1000), -- Comma-separated BCC emails
    subject VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    template_code VARCHAR(50), -- Template used (if any)
    status VARCHAR(20) NOT NULL CHECK (status IN ('PENDING', 'SENT', 'FAILED', 'BOUNCED', 'DELIVERED', 'OPENED', 'CLICKED')),
    error_message VARCHAR(2000), -- Error details if failed
    retry_count INTEGER NOT NULL DEFAULT 0,
    sent_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    sent_by BIGINT, -- User who sent the email
    message_id VARCHAR(255), -- Email provider message ID
    priority VARCHAR(20) CHECK (priority IN ('HIGH', 'NORMAL', 'LOW')) DEFAULT 'NORMAL'
);

-- Create indexes for email_logs
CREATE INDEX idx_emaillog_to_email ON email_logs(to_email);
CREATE INDEX idx_emaillog_status ON email_logs(status);
CREATE INDEX idx_emaillog_template_code ON email_logs(template_code);
CREATE INDEX idx_emaillog_sent_by ON email_logs(sent_by);
CREATE INDEX idx_emaillog_created_at ON email_logs(created_at);
CREATE INDEX idx_emaillog_sent_at ON email_logs(sent_at);
CREATE INDEX idx_emaillog_priority ON email_logs(priority);

-- Add foreign key constraint for template_code (optional, as template might be deleted)
ALTER TABLE email_logs 
ADD CONSTRAINT fk_emaillog_template 
FOREIGN KEY (template_code) REFERENCES email_templates(code) 
ON DELETE SET NULL;

-- Add foreign key constraints for user references (assuming users table exists)
-- These will be added when the users table is available
-- ALTER TABLE email_templates ADD CONSTRAINT fk_emailtemplate_created_by FOREIGN KEY (created_by) REFERENCES users(id);
-- ALTER TABLE email_templates ADD CONSTRAINT fk_emailtemplate_updated_by FOREIGN KEY (updated_by) REFERENCES users(id);
-- ALTER TABLE email_logs ADD CONSTRAINT fk_emaillog_sent_by FOREIGN KEY (sent_by) REFERENCES users(id);

-- Insert some default email templates
INSERT INTO email_templates (name, code, subject, content, template_type, category, description, variables, is_default, enabled, created_at) VALUES
('Welcome Email', 'WELCOME_USER', 'Welcome to {{companyName}}!', 
'<html><body><h1>Welcome {{firstName}}!</h1><p>We are excited to have you join {{companyName}}. Your account has been created successfully.</p><p>Best regards,<br>The {{companyName}} Team</p></body></html>', 
'HTML', 'WELCOME', 'Default welcome email template for new users', 
'["firstName", "companyName"]', TRUE, TRUE, CURRENT_TIMESTAMP),

('Password Reset', 'PASSWORD_RESET', 'Reset Your Password', 
'<html><body><h2>Password Reset Request</h2><p>Hello {{firstName}},</p><p>You have requested to reset your password. Please click the link below to reset your password:</p><p><a href="{{resetLink}}">Reset Password</a></p><p>This link will expire in {{expirationHours}} hours.</p><p>If you did not request this, please ignore this email.</p><p>Best regards,<br>The {{companyName}} Team</p></body></html>', 
'HTML', 'PASSWORD_RESET', 'Password reset email template', 
'["firstName", "resetLink", "expirationHours", "companyName"]', TRUE, TRUE, CURRENT_TIMESTAMP),

('General Notification', 'GENERAL_NOTIFICATION', '{{subject}}', 
'<html><body><h2>{{title}}</h2><p>Hello {{firstName}},</p><p>{{message}}</p><p>Best regards,<br>The {{companyName}} Team</p></body></html>', 
'HTML', 'NOTIFICATION', 'General notification email template', 
'["firstName", "title", "subject", "message", "companyName"]', TRUE, TRUE, CURRENT_TIMESTAMP);

-- Add comments to tables
COMMENT ON TABLE email_templates IS 'Email templates for system-generated emails';
COMMENT ON TABLE email_logs IS 'Log of all emails sent by the system';

COMMENT ON COLUMN email_templates.variables IS 'JSON array of available template variables';
COMMENT ON COLUMN email_templates.is_default IS 'Whether this is the default template for its category';
COMMENT ON COLUMN email_logs.retry_count IS 'Number of times email sending was retried';
COMMENT ON COLUMN email_logs.message_id IS 'Unique message ID from email provider';
</file>

<file path="db/migration/V6__Create_chat_tables.sql">
-- Create chat_rooms table
CREATE TABLE chat_rooms (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100),
    type VARCHAR(20) NOT NULL CHECK (type IN ('DIRECT', 'GROUP', 'CHANNEL')),
    description VARCHAR(500),
    avatar_url VARCHAR(255),
    created_by BIGINT NOT NULL,
    is_private BOOLEAN NOT NULL DEFAULT FALSE,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    last_message_at TIMESTAMP WITH TIME ZONE,
    last_message_id BIGINT
);

-- Create indexes for chat_rooms
CREATE INDEX idx_chatroom_type ON chat_rooms(type);
CREATE INDEX idx_chatroom_created_by ON chat_rooms(created_by);
CREATE INDEX idx_chatroom_active ON chat_rooms(is_active);
CREATE INDEX idx_chatroom_last_message_at ON chat_rooms(last_message_at);

-- Create chat_participants table
CREATE TABLE chat_participants (
    id BIGSERIAL PRIMARY KEY,
    room_id BIGINT NOT NULL,
    user_id BIGINT NOT NULL,
    role VARCHAR(20) NOT NULL CHECK (role IN ('OWNER', 'ADMIN', 'MEMBER')),
    joined_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    last_read_at TIMESTAMP WITH TIME ZONE,
    last_read_message_id BIGINT,
    is_muted BOOLEAN NOT NULL DEFAULT FALSE,
    is_active BOOLEAN NOT NULL DEFAULT TRUE,
    left_at TIMESTAMP WITH TIME ZONE,
    
    CONSTRAINT fk_participant_room FOREIGN KEY (room_id) REFERENCES chat_rooms(id) ON DELETE CASCADE,
    CONSTRAINT uk_participant_room_user UNIQUE (room_id, user_id)
);

-- Create indexes for chat_participants
CREATE INDEX idx_participant_room_id ON chat_participants(room_id);
CREATE INDEX idx_participant_user_id ON chat_participants(user_id);
CREATE INDEX idx_participant_active ON chat_participants(is_active);
CREATE INDEX idx_participant_role ON chat_participants(role);

-- Create chat_messages table
CREATE TABLE chat_messages (
    id BIGSERIAL PRIMARY KEY,
    room_id BIGINT NOT NULL,
    sender_id BIGINT NOT NULL,
    content TEXT,
    message_type VARCHAR(20) DEFAULT 'TEXT' CHECK (message_type IN ('TEXT', 'IMAGE', 'FILE', 'SYSTEM')),
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    is_edited BOOLEAN NOT NULL DEFAULT FALSE,
    edited_at TIMESTAMP WITH TIME ZONE,
    is_deleted BOOLEAN NOT NULL DEFAULT FALSE,
    deleted_at TIMESTAMP WITH TIME ZONE,
    
    CONSTRAINT fk_message_room FOREIGN KEY (room_id) REFERENCES chat_rooms(id) ON DELETE CASCADE
);

-- Create indexes for chat_messages
CREATE INDEX idx_chatmessage_room_id ON chat_messages(room_id);
CREATE INDEX idx_chatmessage_sender_id ON chat_messages(sender_id);
CREATE INDEX idx_chatmessage_created_at ON chat_messages(created_at);
CREATE INDEX idx_chatmessage_deleted ON chat_messages(is_deleted);
CREATE INDEX idx_chatmessage_room_created ON chat_messages(room_id, created_at);

-- Create composite index for efficient message queries
CREATE INDEX idx_chatmessage_room_active ON chat_messages(room_id, is_deleted, created_at);

-- Add foreign key constraint for last_message_id in chat_rooms
ALTER TABLE chat_rooms 
ADD CONSTRAINT fk_room_last_message 
FOREIGN KEY (last_message_id) REFERENCES chat_messages(id) ON DELETE SET NULL;

-- Create function to update updated_at timestamp
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

-- Create trigger to automatically update updated_at for chat_rooms
CREATE TRIGGER update_chat_rooms_updated_at 
    BEFORE UPDATE ON chat_rooms 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();
</file>

<file path="db/migration/V7__Create_notification_tables.sql">
-- Create notifications table (single-table model as per database-design.md)
CREATE TABLE notifications (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    type VARCHAR(50) NOT NULL CHECK (type IN ('SYSTEM', 'ANNOUNCEMENT', 'CHAT_MESSAGE', 'EMAIL', 'TASK_ASSIGNMENT', 'PAYROLL', 'EMPLOYEE_UPDATE', 'DEPARTMENT_UPDATE')),
    priority VARCHAR(20) NOT NULL DEFAULT 'NORMAL' CHECK (priority IN ('LOW', 'NORMAL', 'HIGH', 'URGENT')),
    is_read BOOLEAN NOT NULL DEFAULT FALSE,
    read_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    sender_id BIGINT,
    reference_id BIGINT,
    reference_type VARCHAR(50),
    action_url VARCHAR(500),
    metadata TEXT,
    expires_at TIMESTAMP WITH TIME ZONE
);

-- Create indexes for notifications
CREATE INDEX idx_notification_user_id ON notifications(user_id);
CREATE INDEX idx_notification_type ON notifications(type);
CREATE INDEX idx_notification_is_read ON notifications(is_read);
CREATE INDEX idx_notification_created_at ON notifications(created_at);
CREATE INDEX idx_notification_user_read ON notifications(user_id, is_read);
CREATE INDEX idx_notification_sender_id ON notifications(sender_id);
CREATE INDEX idx_notification_reference ON notifications(reference_type, reference_id);
CREATE INDEX idx_notification_expires_at ON notifications(expires_at);

-- Create announcements table
CREATE TABLE announcements (
    id BIGSERIAL PRIMARY KEY,
    title VARCHAR(200) NOT NULL,
    content TEXT NOT NULL,
    author_id BIGINT NOT NULL,
    target_audience VARCHAR(50) CHECK (target_audience IN ('ALL', 'DEPARTMENT', 'ROLE')),
    department_id BIGINT,
    role_name VARCHAR(100),
    publish_date DATE,
    expiry_date DATE,
    published BOOLEAN NOT NULL DEFAULT FALSE,
    priority VARCHAR(20) NOT NULL DEFAULT 'NORMAL' CHECK (priority IN ('LOW', 'NORMAL', 'HIGH', 'URGENT')),
    created_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT
);

-- Create indexes for announcements
CREATE INDEX idx_announcement_author_id ON announcements(author_id);
CREATE INDEX idx_announcement_target_audience ON announcements(target_audience);
CREATE INDEX idx_announcement_department_id ON announcements(department_id);
CREATE INDEX idx_announcement_published ON announcements(published);
CREATE INDEX idx_announcement_publish_date ON announcements(publish_date);
CREATE INDEX idx_announcement_expiry_date ON announcements(expiry_date);
CREATE INDEX idx_announcement_priority ON announcements(priority);

-- Create function to automatically create notifications for published announcements
CREATE OR REPLACE FUNCTION create_announcement_notifications()
RETURNS TRIGGER AS $$
DECLARE
    target_user_id BIGINT;
BEGIN
    -- Only create notifications when announcement is published
    IF NEW.published = TRUE AND (OLD IS NULL OR OLD.published = FALSE) THEN
        -- Create notifications based on target audience
        IF NEW.target_audience = 'ALL' THEN
            -- Create notifications for all active employees
            INSERT INTO notifications (user_id, title, content, type, priority, sender_id, reference_id, reference_type, action_url)
            SELECT 
                e.id,
                'New Announcement: ' || NEW.title,
                NEW.content,
                'ANNOUNCEMENT',
                NEW.priority::VARCHAR,
                NEW.author_id,
                NEW.id,
                'ANNOUNCEMENT',
                '/announcements/' || NEW.id
            FROM employees e 
            WHERE e.status = 'ACTIVE';
            
        ELSIF NEW.target_audience = 'DEPARTMENT' AND NEW.department_id IS NOT NULL THEN
            -- Create notifications for employees in specific department
            INSERT INTO notifications (user_id, title, content, type, priority, sender_id, reference_id, reference_type, action_url)
            SELECT 
                e.id,
                'New Announcement: ' || NEW.title,
                NEW.content,
                'ANNOUNCEMENT',
                NEW.priority::VARCHAR,
                NEW.author_id,
                NEW.id,
                'ANNOUNCEMENT',
                '/announcements/' || NEW.id
            FROM employees e 
            WHERE e.department_id = NEW.department_id AND e.status = 'ACTIVE';
            
        ELSIF NEW.target_audience = 'ROLE' AND NEW.role_name IS NOT NULL THEN
            -- Create notifications for users with specific role
            INSERT INTO notifications (user_id, title, content, type, priority, sender_id, reference_id, reference_type, action_url)
            SELECT 
                u.id,
                'New Announcement: ' || NEW.title,
                NEW.content,
                'ANNOUNCEMENT',
                NEW.priority::VARCHAR,
                NEW.author_id,
                NEW.id,
                'ANNOUNCEMENT',
                '/announcements/' || NEW.id
            FROM users u 
            JOIN user_roles ur ON u.id = ur.user_id
            JOIN roles r ON ur.role_id = r.id
            WHERE r.name = NEW.role_name AND u.enabled = TRUE;
        END IF;
    END IF;
    
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create trigger for announcement notifications
CREATE TRIGGER trigger_announcement_notifications
    AFTER INSERT OR UPDATE ON announcements
    FOR EACH ROW
    EXECUTE FUNCTION create_announcement_notifications();

-- Create trigger to automatically update updated_at for announcements
CREATE TRIGGER update_announcements_updated_at 
    BEFORE UPDATE ON announcements 
    FOR EACH ROW 
    EXECUTE FUNCTION update_updated_at_column();

-- Create function to clean up expired notifications
CREATE OR REPLACE FUNCTION cleanup_expired_notifications()
RETURNS INTEGER AS $$
DECLARE
    deleted_count INTEGER;
BEGIN
    DELETE FROM notifications 
    WHERE expires_at IS NOT NULL AND expires_at < CURRENT_TIMESTAMP;
    
    GET DIAGNOSTICS deleted_count = ROW_COUNT;
    RETURN deleted_count;
END;
$$ LANGUAGE plpgsql;

-- Create function to mark notification as read
CREATE OR REPLACE FUNCTION mark_notification_read(notification_id BIGINT, user_id BIGINT)
RETURNS BOOLEAN AS $$
DECLARE
    updated_count INTEGER;
BEGIN
    UPDATE notifications 
    SET is_read = TRUE, read_at = CURRENT_TIMESTAMP
    WHERE id = notification_id AND user_id = user_id AND is_read = FALSE;
    
    GET DIAGNOSTICS updated_count = ROW_COUNT;
    RETURN updated_count > 0;
END;
$$ LANGUAGE plpgsql;
</file>

<file path="db/migration/V8__Create_payroll_tables.sql">
-- Create payroll management tables
-- This migration creates tables for payroll ledgers, periods, salary components, and audit trails

-- Create payroll_periods table
CREATE TABLE payroll_periods (
    id BIGSERIAL PRIMARY KEY,
    period_name VARCHAR(100) NOT NULL,
    start_date DATE NOT NULL,
    end_date DATE NOT NULL,
    period_type VARCHAR(20) NOT NULL CHECK (period_type IN ('MONTHLY', 'BI_WEEKLY', 'WEEKLY', 'CUSTOM')),
    status VARCHAR(20) NOT NULL DEFAULT 'OPEN' CHECK (status IN ('OPEN', 'PROCESSING', 'CLOSED', 'CANCELLED')),
    pay_date DATE,
    description VARCHAR(500),
    is_active BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Constraints
    CONSTRAINT chk_payroll_period_dates CHECK (end_date >= start_date),
    CONSTRAINT chk_payroll_period_pay_date CHECK (pay_date IS NULL OR pay_date >= end_date)
);

-- Create salary_components table
CREATE TABLE salary_components (
    id BIGSERIAL PRIMARY KEY,
    component_name VARCHAR(100) NOT NULL,
    component_type VARCHAR(50) NOT NULL CHECK (component_type IN ('EARNING', 'DEDUCTION', 'TAX')),
    amount DECIMAL(15,2) NOT NULL DEFAULT 0.00 CHECK (amount >= 0),
    percentage DECIMAL(5,2) CHECK (percentage >= 0 AND percentage <= 100),
    is_taxable BOOLEAN NOT NULL DEFAULT false,
    is_mandatory BOOLEAN NOT NULL DEFAULT false,
    calculation_order INTEGER NOT NULL DEFAULT 0,
    description VARCHAR(500),
    is_active BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Constraints
    CONSTRAINT uk_salary_component_name UNIQUE (component_name),
    CONSTRAINT chk_salary_component_amount_or_percentage CHECK (
        (amount > 0 AND percentage IS NULL) OR 
        (amount = 0 AND percentage IS NOT NULL AND percentage > 0)
    )
);

-- Create payroll_ledgers table
CREATE TABLE payroll_ledgers (
    id BIGSERIAL PRIMARY KEY,
    employee_id BIGINT NOT NULL,
    payroll_period_id BIGINT NOT NULL,
    base_salary DECIMAL(15,2) NOT NULL CHECK (base_salary >= 0),
    gross_pay DECIMAL(15,2) DEFAULT 0.00 CHECK (gross_pay >= 0),
    total_deductions DECIMAL(15,2) DEFAULT 0.00 CHECK (total_deductions >= 0),
    total_taxes DECIMAL(15,2) DEFAULT 0.00 CHECK (total_taxes >= 0),
    net_pay DECIMAL(15,2) DEFAULT 0.00 CHECK (net_pay >= 0),
    overtime_hours DECIMAL(8,2) DEFAULT 0.00 CHECK (overtime_hours >= 0),
    overtime_pay DECIMAL(15,2) DEFAULT 0.00 CHECK (overtime_pay >= 0),
    bonus_amount DECIMAL(15,2) DEFAULT 0.00 CHECK (bonus_amount >= 0),
    status VARCHAR(20) NOT NULL DEFAULT 'PENDING' CHECK (status IN ('PENDING', 'CALCULATED', 'APPROVED', 'PAID', 'REJECTED', 'CANCELLED')),
    payment_method VARCHAR(20) CHECK (payment_method IN ('BANK_TRANSFER', 'CHECK', 'CASH', 'OTHER')),
    pay_date DATE,
    payment_reference VARCHAR(100),
    notes VARCHAR(1000),
    approved_by BIGINT,
    approved_at TIMESTAMP,
    paid_by BIGINT,
    paid_at TIMESTAMP,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    created_by BIGINT,
    updated_by BIGINT,
    
    -- Foreign key constraints
    CONSTRAINT fk_payroll_ledger_employee FOREIGN KEY (employee_id) REFERENCES employees(id) ON DELETE CASCADE,
    CONSTRAINT fk_payroll_ledger_period FOREIGN KEY (payroll_period_id) REFERENCES payroll_periods(id) ON DELETE CASCADE,
    CONSTRAINT fk_payroll_ledger_approved_by FOREIGN KEY (approved_by) REFERENCES users(id),
    CONSTRAINT fk_payroll_ledger_paid_by FOREIGN KEY (paid_by) REFERENCES users(id),
    CONSTRAINT fk_payroll_ledger_created_by FOREIGN KEY (created_by) REFERENCES users(id),
    CONSTRAINT fk_payroll_ledger_updated_by FOREIGN KEY (updated_by) REFERENCES users(id),
    
    -- Business constraints
    CONSTRAINT uk_payroll_ledger_employee_period UNIQUE (employee_id, payroll_period_id),
    CONSTRAINT chk_payroll_ledger_net_pay CHECK (net_pay = gross_pay - total_deductions - total_taxes),
    CONSTRAINT chk_payroll_ledger_approval CHECK (
        (status != 'APPROVED' AND approved_by IS NULL AND approved_at IS NULL) OR
        (status = 'APPROVED' AND approved_by IS NOT NULL AND approved_at IS NOT NULL)
    ),
    CONSTRAINT chk_payroll_ledger_payment CHECK (
        (status != 'PAID' AND paid_by IS NULL AND paid_at IS NULL AND payment_reference IS NULL) OR
        (status = 'PAID' AND paid_by IS NOT NULL AND paid_at IS NOT NULL)
    )
);

-- Create payroll_ledger_components table for detailed salary breakdowns
CREATE TABLE payroll_ledger_components (
    id BIGSERIAL PRIMARY KEY,
    payroll_ledger_id BIGINT NOT NULL,
    salary_component_id BIGINT NOT NULL,
    amount DECIMAL(15,2) NOT NULL CHECK (amount >= 0),
    calculated_amount DECIMAL(15,2) NOT NULL CHECK (calculated_amount >= 0),
    percentage_applied DECIMAL(5,2) CHECK (percentage_applied >= 0 AND percentage_applied <= 100),
    is_override BOOLEAN NOT NULL DEFAULT false,
    override_reason VARCHAR(500),
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    -- Foreign key constraints
    CONSTRAINT fk_payroll_component_ledger FOREIGN KEY (payroll_ledger_id) REFERENCES payroll_ledgers(id) ON DELETE CASCADE,
    CONSTRAINT fk_payroll_component_salary FOREIGN KEY (salary_component_id) REFERENCES salary_components(id) ON DELETE CASCADE,
    
    -- Unique constraint
    CONSTRAINT uk_payroll_component_ledger_salary UNIQUE (payroll_ledger_id, salary_component_id)
);

-- Create payroll_audits table for change tracking
CREATE TABLE payroll_audits (
    id BIGSERIAL PRIMARY KEY,
    payroll_ledger_id BIGINT NOT NULL,
    action VARCHAR(50) NOT NULL CHECK (action IN ('CREATED', 'CALCULATED', 'APPROVED', 'PAID', 'REJECTED', 'CANCELLED', 'UPDATED')),
    old_status VARCHAR(20),
    new_status VARCHAR(20),
    changes TEXT, -- JSON string of changes
    reason VARCHAR(500),
    performed_by BIGINT NOT NULL,
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    
    -- Foreign key constraints
    CONSTRAINT fk_payroll_audit_ledger FOREIGN KEY (payroll_ledger_id) REFERENCES payroll_ledgers(id) ON DELETE CASCADE,
    CONSTRAINT fk_payroll_audit_performed_by FOREIGN KEY (performed_by) REFERENCES users(id)
);

-- Create indexes for performance optimization
CREATE INDEX idx_payroll_periods_status ON payroll_periods(status);
CREATE INDEX idx_payroll_periods_dates ON payroll_periods(start_date, end_date);
CREATE INDEX idx_payroll_periods_active ON payroll_periods(is_active);

CREATE INDEX idx_salary_components_type ON salary_components(component_type);
CREATE INDEX idx_salary_components_active ON salary_components(is_active);
CREATE INDEX idx_salary_components_order ON salary_components(calculation_order);

CREATE INDEX idx_payroll_ledger_employee_id ON payroll_ledgers(employee_id);
CREATE INDEX idx_payroll_ledger_period_id ON payroll_ledgers(payroll_period_id);
CREATE INDEX idx_payroll_ledger_status ON payroll_ledgers(status);
CREATE INDEX idx_payroll_ledger_pay_date ON payroll_ledgers(pay_date);
CREATE INDEX idx_payroll_ledger_created_at ON payroll_ledgers(created_at);

CREATE INDEX idx_payroll_component_ledger_id ON payroll_ledger_components(payroll_ledger_id);
CREATE INDEX idx_payroll_component_salary_id ON payroll_ledger_components(salary_component_id);

CREATE INDEX idx_payroll_audit_ledger_id ON payroll_audits(payroll_ledger_id);
CREATE INDEX idx_payroll_audit_action ON payroll_audits(action);
CREATE INDEX idx_payroll_audit_created_at ON payroll_audits(created_at);
CREATE INDEX idx_payroll_audit_performed_by ON payroll_audits(performed_by);

-- Insert default salary components
INSERT INTO salary_components (component_name, component_type, amount, is_taxable, is_mandatory, calculation_order, description) VALUES
('Basic Salary', 'EARNING', 0.00, true, true, 1, 'Base salary component'),
('House Rent Allowance', 'EARNING', 0.00, true, false, 2, 'Housing allowance'),
('Transport Allowance', 'EARNING', 0.00, false, false, 3, 'Transportation allowance'),
('Medical Allowance', 'EARNING', 0.00, false, false, 4, 'Medical benefits allowance'),
('Performance Bonus', 'EARNING', 0.00, true, false, 5, 'Performance-based bonus'),
('Overtime Pay', 'EARNING', 0.00, true, false, 6, 'Overtime compensation'),

('Income Tax', 'TAX', 0.00, false, true, 10, 'Federal income tax'),
('Social Security Tax', 'TAX', 0.00, false, true, 11, 'Social security contribution'),
('Medicare Tax', 'TAX', 0.00, false, true, 12, 'Medicare contribution'),
('State Tax', 'TAX', 0.00, false, false, 13, 'State income tax'),

('Health Insurance', 'DEDUCTION', 0.00, false, false, 20, 'Health insurance premium'),
('Life Insurance', 'DEDUCTION', 0.00, false, false, 21, 'Life insurance premium'),
('Retirement Fund', 'DEDUCTION', 0.00, false, false, 22, 'Retirement savings contribution'),
('Union Dues', 'DEDUCTION', 0.00, false, false, 23, 'Union membership dues'),
('Loan Repayment', 'DEDUCTION', 0.00, false, false, 24, 'Employee loan repayment');

-- Add comments for documentation
COMMENT ON TABLE payroll_periods IS 'Payroll periods for organizing payroll processing cycles';
COMMENT ON TABLE salary_components IS 'Configurable salary components for earnings, deductions, and taxes';
COMMENT ON TABLE payroll_ledgers IS 'Individual employee payroll records for each pay period';
COMMENT ON TABLE payroll_ledger_components IS 'Detailed breakdown of salary components for each payroll ledger';
COMMENT ON TABLE payroll_audits IS 'Audit trail for all payroll-related changes and actions';

COMMENT ON COLUMN payroll_ledgers.net_pay IS 'Calculated as gross_pay - total_deductions - total_taxes';
COMMENT ON COLUMN payroll_audits.changes IS 'JSON string containing detailed change information';
COMMENT ON COLUMN salary_components.calculation_order IS 'Order in which components are calculated (lower numbers first)';
</file>

<file path="logback-spring-simple.xml">
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    
    <!-- Console Appender -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- File Appender -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/employee-management.log</file>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>logs/employee-management.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <maxFileSize>50MB</maxFileSize>
            <maxHistory>30</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- Root Logger -->
    <springProfile name="dev">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="FILE"/>
        </root>
    </springProfile>
    
    <springProfile name="!dev">
        <root level="WARN">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="FILE"/>
        </root>
    </springProfile>
    
</configuration>
</file>

<file path="logback-spring.xml">
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    
    <!-- 控制台输出 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- 文件输出 -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/employee-management.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/employee-management.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- 错误日志 -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/error.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>logs/error.%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- 环境特定的根日志配置 -->
    <springProfile name="dev,local,hybrid">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>
    
    <springProfile name="prod,staging">
        <root level="WARN">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>
    
    <!-- Spring框架日志 -->
    <logger name="org.springframework" level="WARN"/>
    <logger name="org.springframework.security" level="DEBUG"/>
    <logger name="org.hibernate.SQL" level="DEBUG"/>
    
    <!-- 应用日志 -->
    <logger name="com.example.demo" level="DEBUG"/>

</configuration>
</file>

<file path="logback-spring.xml.backup">
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <include resource="org/springframework/boot/logging/logback/defaults.xml"/>
    
    <!-- Define properties -->
    <springProperty scope="context" name="LOG_FILE" source="logging.file.name" defaultValue="logs/employee-management.log"/>
    <springProperty scope="context" name="LOG_LEVEL" source="logging.level.com.example.demo" defaultValue="INFO"/>
    <springProperty scope="context" name="APP_NAME" source="spring.application.name" defaultValue="employee-management"/>
    
    <!-- Console Appender -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{HH:mm:ss.SSS} [%thread] %highlight(%-5level) %cyan(%logger{36}) - %msg%n</pattern>
        </encoder>
    </appender>
    
    <!-- File Appender -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_FILE}</file>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>${LOG_FILE}.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <maxFileSize>50MB</maxFileSize>
            <maxHistory>30</maxHistory>
            <totalSizeCap>1GB</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- Security Audit Appender -->
    <appender name="SECURITY_AUDIT" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/security-audit.log</file>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{userId},%X{sessionId}] %logger{36} - %msg%n</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>logs/security-audit.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <maxFileSize>20MB</maxFileSize>
            <maxHistory>90</maxHistory>
            <totalSizeCap>500MB</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- Business Audit Appender -->
    <appender name="BUSINESS_AUDIT" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/business-audit.log</file>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%X{userId}] %logger{36} - %msg%n</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>logs/business-audit.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <maxFileSize>20MB</maxFileSize>
            <maxHistory>365</maxHistory>
            <totalSizeCap>2GB</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- Error Appender -->
    <appender name="ERROR_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/error.log</file>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>ACCEPT</onMatch>
            <onMismatch>DENY</onMismatch>
        </filter>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{traceId},%X{spanId}] %logger{36} - %msg%n</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>logs/error.%d{yyyy-MM-dd}.%i.gz</fileNamePattern>
            <maxFileSize>10MB</maxFileSize>
            <maxHistory>30</maxHistory>
            <totalSizeCap>300MB</totalSizeCap>
        </rollingPolicy>
    </appender>
    
    <!-- Async Appenders for Performance -->
    <appender name="ASYNC_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="FILE"/>
        <queueSize>512</queueSize>
        <discardingThreshold>0</discardingThreshold>
        <includeCallerData>true</includeCallerData>
    </appender>
    
    <appender name="ASYNC_SECURITY_AUDIT" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="SECURITY_AUDIT"/>
        <queueSize>256</queueSize>
        <discardingThreshold>0</discardingThreshold>
    </appender>
    
    <!-- Logger Configurations -->
    
    <!-- Security Logger -->
    <logger name="com.example.demo.security" level="INFO" additivity="false">
        <appender-ref ref="ASYNC_SECURITY_AUDIT"/>
        <appender-ref ref="CONSOLE"/>
    </logger>
    
    <!-- Business Audit Logger -->
    <logger name="BUSINESS_AUDIT" level="INFO" additivity="false">
        <appender-ref ref="BUSINESS_AUDIT"/>
    </logger>
    
    <!-- SQL Logging (Production: OFF, Staging: DEBUG) -->
    <springProfile name="!prod">
        <logger name="org.hibernate.SQL" level="DEBUG"/>
        <logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE"/>
    </springProfile>
    
    <!-- Framework Loggers -->
    <logger name="org.springframework.security" level="WARN"/>
    <logger name="org.springframework.web" level="WARN"/>
    <logger name="org.flywaydb" level="INFO"/>
    <logger name="redis.clients.jedis" level="WARN"/>
    <logger name="org.apache.http" level="WARN"/>
    
    <!-- Application Loggers -->
    <logger name="com.example.demo.payroll" level="INFO"/>
    <logger name="com.example.demo.employee" level="INFO"/>
    <logger name="com.example.demo.department" level="INFO"/>
    <logger name="com.example.demo.communication" level="INFO"/>
    
    <!-- Root Logger -->
    <springProfile name="dev">
        <root level="DEBUG">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>
    
    <springProfile name="staging">
        <root level="INFO">
            <appender-ref ref="CONSOLE"/>
            <appender-ref ref="ASYNC_FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>
    
    <springProfile name="prod">
        <root level="WARN">
            <appender-ref ref="ASYNC_FILE"/>
            <appender-ref ref="ERROR_FILE"/>
        </root>
    </springProfile>
    
</configuration>
</file>

<file path="static/.gitkeep">
# This file ensures the static directory is tracked by Git
# Static web assets (for React build) will be placed in this directory
</file>

<file path="templates/.gitkeep">
# This file ensures the templates directory is tracked by Git
# Email templates (Freemarker .ftl files) will be placed in this directory
</file>

</files>
